from openai import OpenAI
client = OpenAI()

import streamlit as st
from elevenlabs import set_api_key, generate, save
import os
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase
import queue
import av
import tempfile

# Configuration des clÃ©s API
set_api_key(os.getenv("ELEVENLABS_API_KEY"))

st.set_page_config("ğŸ§ Podcast Live IA", layout="centered")
st.title("ğŸ§ Podcast interactif en direct : IsraÃ«l - Iran")

# Ã‰coute du podcast
st.subheader("ğŸ™ Ã‰coutez le podcast")
st.audio("podcast.mp3", format="audio/mp3")

st.subheader("ğŸ¤ Posez une question Ã  voix haute (micro en direct)")

# Gestion audio live
class AudioProcessor(AudioProcessorBase):
    def __init__(self):
        self.buffer = queue.Queue()

    def recv(self, frame: av.AudioFrame) -> av.AudioFrame:
        pcm = frame.to_ndarray().flatten().astype("int16").tobytes()
        self.buffer.put(pcm)
        return frame

ctx = webrtc_streamer(
    key="speech-to-text",
    audio_processor_factory=AudioProcessor,
    media_stream_constraints={"audio": True, "video": False},
    async_processing=True,
)

if ctx.state.playing:
    st.info("ğŸ™ï¸ Parlez maintenant...")
    if ctx.audio_processor:
        audio_data = b""
        while not ctx.audio_processor.buffer.empty():
            audio_data += ctx.audio_processor.buffer.get()

        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
            f.write(audio_data)
            wav_path = f.name

        if wav_path:
            with st.spinner("ğŸ” Transcription en cours..."):
                with open(wav_path, "rb") as audio_file:
                    transcript = client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio_file
                    )
                st.markdown(f"ğŸ“ **Vous avez dit** : {transcript.text}")

                with st.spinner("ğŸ’¬ RÃ©ponse de lâ€™IA..."):
                    chat = client.chat.completions.create(
                        model="gpt-4o",
                        messages=[
                            {"role": "system", "content": "Tu es un expert en gÃ©opolitique, parle simplement."},
                            {"role": "user", "content": transcript.text}
                        ]
                    )
                    reply = chat.choices[0].message.content
                    st.markdown(f"ğŸ§  **RÃ©ponse IA** : {reply}")

                with st.spinner("ğŸ”Š SynthÃ¨se vocale..."):
                    audio = generate(text=reply, voice="Bella", model="eleven_multilingual_v1")
                    save(audio, "ia-response.mp3")
                    st.audio("ia-response.mp3", format="audio/mp3")

st.audio("", format="audio/mp3")  # coupe l'audio actif

